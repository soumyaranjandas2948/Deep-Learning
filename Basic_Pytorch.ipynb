{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction"
      ],
      "metadata": {
        "id": "dErl1Xuimwn9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Deep Learning workflows*\n",
        "\n",
        "1. Data\n",
        "2. Create a Model\n",
        "3. Optimize Model paramter (finding the best weights)\n",
        "4. Save the trained model"
      ],
      "metadata": {
        "id": "J9kxJedKm-KA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing the libraries"
      ],
      "metadata": {
        "id": "YKbi2-bwneG4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor"
      ],
      "metadata": {
        "id": "JWegG5yTm66U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download the data"
      ],
      "metadata": {
        "id": "B9MFOzHdo7IG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_data = datasets.FashionMNIST(root = 'data',train = True,download = True,transform = ToTensor())\n",
        "test_data = datasets.FashionMNIST(root = 'data',train = False,download = True,transform = ToTensor())"
      ],
      "metadata": {
        "id": "d9r1Xdsro49P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_data"
      ],
      "metadata": {
        "id": "wuBCzqDDpaEN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data"
      ],
      "metadata": {
        "id": "oqpNW7l3qKix"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Batching of this data"
      ],
      "metadata": {
        "id": "ktfU1xvHqeW3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "train_dataloader = DataLoader(training_data,batch_size = batch_size)\n",
        "test_dataloader = DataLoader(test_data,batch_size = batch_size)"
      ],
      "metadata": {
        "id": "KB_7iEpcqSNL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for x,y in test_dataloader:\n",
        "  print(\"Input Image Shape : \",x.shape)\n",
        "  print(\"Label Shape : \",y.shape)\n",
        "  break"
      ],
      "metadata": {
        "id": "0jvgKi54uBHh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Input Image Shape :  torch.Size([64, 1, 28, 28])\n",
        "Batch Size (64):This is the number of samples in each batch. In the context of neural networks, training is often done in batches to improve efficiency.\n",
        "\n",
        "Number of Channels (1): For grayscale or black-and-white images, the number of channels is typically 1. For color images, you would typically have 3 channels (red, green, and blue).\n",
        "\n",
        "Height (28): This is the height of the image in pixels.\n",
        "\n",
        "Width (28): This is the width of the image in pixels.\n",
        "\n",
        "Label Shape :  torch.Size([64]) -- Label\n"
      ],
      "metadata": {
        "id": "uzxGoc6YurCo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating the Model"
      ],
      "metadata": {
        "id": "cq7mTvAfxVsl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#torch.cuda.is_available() checks for your system has gpu or cpu\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device"
      ],
      "metadata": {
        "id": "tc6lIh2sujKq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNetwork(nn.Module): #nn.Module is a parent class\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.flatten = nn.Flatten() #28*28 image into a 764*1 vector\n",
        "    self.linear1 = nn.Linear(28*28,512)\n",
        "    self.linear2 = nn.Linear(512,512)\n",
        "    self.linear3 = nn.Linear(512,10)\n",
        "    self.relu = nn.ReLU()\n",
        "  def forward(self,x): #is always used to pass the inputs to the neural network\n",
        "    x = self.flatten(x)\n",
        "    x = self.linear1(x)\n",
        "    x = self.relu(x)\n",
        "    x = self.linear2(x)\n",
        "    x = self.relu(x)\n",
        "    x = self.linear3(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "kEwiE_8lx0nv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = NeuralNetwork()\n",
        "model = model.to(device) #copies your entire architecture to the GPU"
      ],
      "metadata": {
        "id": "tZ6fICUX8L9Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Optimization - Gradient Descent + Backpropagation"
      ],
      "metadata": {
        "id": "wF6POqp36yEx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(),lr = 1e-3)"
      ],
      "metadata": {
        "id": "2pNwn5Gs1ShC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#steps in the GD : Batch of the input / Pass it to the model / Compute loss function / Update the weights\n",
        "def train(dataloader,model,loss_fn,optimizer):\n",
        "  model.train()  #putting the model in the training mode\n",
        "  for batch,(x,y) in enumerate(dataloader):\n",
        "    #sending data to GPU\n",
        "    x = x.to(device)\n",
        "    y = y.to(device)\n",
        "\n",
        "    #compute Predictions\n",
        "    pred = model(x)\n",
        "\n",
        "    #compute Loss\n",
        "    loss = loss_fn(pred,y)\n",
        "\n",
        "    #Backpropagation\n",
        "    loss.backward()\n",
        "    optimizer.step() #Wnew = Wold - lr * dl/dw\n",
        "    optimizer.zero_grad() # If you don't zero the gradients, the new gradients will be accumulated with the existing ones, leading to incorrect updates.\n",
        "\n",
        "    if batch % 100 == 0:\n",
        "      print(f'Loss of the Model{loss.item()}')"
      ],
      "metadata": {
        "id": "_K5wU1dr8IlN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(dataloader,model,loss_fn):\n",
        "  model.eval() #putting the model in the evaluation mode\n",
        "  num_batched = len(dataloader)\n",
        "  test_loss, correct = 0,0\n",
        "  with torch.no_grad(): #We will not compute gradients for the test data\n",
        "    for X,y in dataloader:\n",
        "      X = X.to(device)\n",
        "      y = y.to(device)\n",
        "\n",
        "      #Compute predictions\n",
        "      pred = model(X)\n",
        "\n",
        "      #Compute loss\n",
        "      test_loss += loss_fn(pred,y).item()\n",
        "\n",
        "      #Find how many correct predictions\n",
        "      correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "  test_loss = test_loss/num_batched\n",
        "  correct = correct/(len(dataloader.dataset))\n",
        "\n",
        "  print(f'Test Accuracy {100*correct}, Avg_loss : {test_loss}')"
      ],
      "metadata": {
        "id": "eqdbgHZ5GJxQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# model.train() --\n",
        " This method is used to set the model in training mode. When the model is in training mode, certain layers (e.g., dropout layers) may behave differently compared to when the model is in evaluation mode. During training, dropout layers are active, introducing randomness to the network by randomly dropping units.\n",
        "# Dropout Layers\n",
        "Dropout is a regularization technique used in neural networks during training to prevent overfitting. It involves randomly setting a fraction of input units to zero at each update during training time, which helps prevent the network from relying too much on specific units. Dropout is typically applied to the input or hidden layers of a neural network.\n",
        "# During Training\n",
        "For each training batch, dropout randomly sets a fraction (e.g., 20%) of the input units to zero.\n",
        "This means that the contribution of those units is temporarily removed, and the network must learn to rely on the remaining units to make predictions.\n",
        "# model.eval()\n",
        "This method is used to set the model in evaluation mode. In evaluation mode, layers like dropout layers are typically deactivated.\n",
        "# During Testing or Inference:\n",
        "During testing or inference, dropout is turned off, and all units are used.\n",
        "The idea is that during testing, you want the model to use all the learned information for making predictions without introducing randomness.\n"
      ],
      "metadata": {
        "id": "SwixKDOMMHoH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training Phase"
      ],
      "metadata": {
        "id": "VHp2y20EOtEK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 5\n",
        "for t in range(epochs):\n",
        "  print(f'Epoch {t+1}')\n",
        "  train(train_dataloader,model,loss_fn,optimizer)\n",
        "  test(test_dataloader,model,loss_fn)"
      ],
      "metadata": {
        "id": "yfrWNehLGqxX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save the Model"
      ],
      "metadata": {
        "id": "iGpTfrviSvsm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(),\"/content/data.pth\")"
      ],
      "metadata": {
        "id": "uSUu2L2ZQbdc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading the saved weights"
      ],
      "metadata": {
        "id": "DoxWY0-tVevl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = NeuralNetwork().to(device)\n",
        "model.load_state_dict(torch.load(\"/content/data.pth\"))"
      ],
      "metadata": {
        "id": "XpW6tfMrTEqz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preidctions"
      ],
      "metadata": {
        "id": "eGjoTuzsWYxc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classes = [\"T-shirt/top\",\"Trouser\",\"Pullover\",\"Dress\",\"Coat\",\"Sandal\",\"Shirt\",\"Sneaker\",\"Bag\",\"Ankle Boot\"]\n",
        "\n",
        "model.eval()\n",
        "X,y = test_data[0][0], test_data[0][1]\n",
        "\n",
        "with torch.no_grad():\n",
        "  X = X.to(device)\n",
        "  pred = model(X)\n",
        "  predicted,actual = classes[pred[0].argmax(0)],classes[y]\n",
        "  print(f'Predicted {predicted}')\n",
        "  print(f'Actual {actual}')"
      ],
      "metadata": {
        "id": "Su5l3IctWQoA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "id": "MFqPU2JpWyzq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SklvCiqCW7Cb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}